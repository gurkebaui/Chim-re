import torch
from mamba_ssm import Mamba

def run_test():
    """
    Ein schnelles Skript zum Testen der PyTorch- und Mamba-SSM-Installation auf der GPU.
    """
    print("--- Test f√ºr Mamba-SSM Installation ---")

    # 1. √úberpr√ºfe die GPU-Verf√ºgbarkeit
    if not torch.cuda.is_available():
        print("‚ùå FEHLER: CUDA ist nicht verf√ºgbar. PyTorch kann die GPU nicht finden.")
        return

    device = "cuda"
    gpu_name = torch.cuda.get_device_name(0)
    print(f"‚úÖ GPU gefunden: {gpu_name}")

    try:
        # 2. Definiere Modellparameter und erstelle einen Dummy-Input
        batch_size = 4
        seq_length = 256
        d_model = 64  # Modelldimension

        # Erstelle einen zuf√§lligen Tensor auf der GPU
        input_tensor = torch.randn(batch_size, seq_length, d_model, device=device)
        print(f"\n‚úÖ Dummy-Input-Tensor erstellt mit Shape: {input_tensor.shape}")

        # 3. Initialisiere das Mamba-Modell
        print("   Initialisiere das Mamba-Modell...")
        model = Mamba(
            d_model=d_model,
            d_state=16,
            d_conv=4,
            expand=2,
        ).to(device)
        print("‚úÖ Mamba-Modell erfolgreich initialisiert und auf die GPU verschoben.")

        # 4. F√ºhre einen Forward Pass durch
        print("   F√ºhre einen Forward Pass aus...")
        # Wir brauchen keine Gradienten f√ºr diesen Test
        with torch.no_grad():
            output_tensor = model(input_tensor)
        
        print("‚úÖ Forward Pass erfolgreich abgeschlossen.")
        print(f"‚úÖ Output-Tensor hat den Shape: {output_tensor.shape}")

        # 5. Finale √úberpr√ºfung
        if output_tensor.shape == input_tensor.shape:
            print("\nüéâ ERFOLG! Deine PyTorch- und Mamba-SSM-Installation scheint korrekt auf der GPU zu funktionieren.")
        else:
            print(f"\n‚ö†Ô∏è WARNUNG: Der Output-Shape {output_tensor.shape} stimmt nicht mit dem Input-Shape {input_tensor.shape} √ºberein.")

    except Exception as e:
        print(f"\n‚ùå Ein Fehler ist w√§hrend des Tests aufgetreten: {e}")
        print("   Das k√∂nnte auf ein Problem mit den CUDA-Kernels, eine fehlerhafte Kompilierung oder eine Versions-Inkompatibilit√§t hindeuten.")

if __name__ == "__main__":
    run_test()